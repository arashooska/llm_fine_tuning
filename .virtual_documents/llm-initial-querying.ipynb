from dotenv import load_dotenv
import pandas as pd
import json
import os


#For now, load in the whole df and then filter it down to the relevant rows
def get_data(fname):
    with open("./datasets/fa.json", "r", encoding="utf-8") as f:
        #json.dump(data, f, indent=4, ensure_ascii=False)
        data = json.load(f)


# Load environment variables from .env file
load_dotenv()

# Access the API key
llama_api_key = os.getenv("LLAMA_API_KEY")


print(llama_api_key)


from llamaapi import LlamaAPI


llm = LlamaAPI(llama_api_key)


# API Request JSON Cell
api_request_json = {
  "model": "llama-13b-chat",
  "messages": [
    {"role": "system", "content": "You are a llama assistant that talks like a llama, starting every word with 'll'."},
    {"role": "user", "content": "Hi, happy llama day!"},
  ]
}

#Make your request and handle the response
response = llm.run(api_request_json)
print(json.dumps(response.json(), indent=2))


api_request_json_farsi = {
  "model": "llama-13b-chat",
  "messages": [
    {"role": "system", "content": "You are a Farsi chatbot. Respond to the Farsi query with a Farsi response."},
    {"role": "user", "content": "سلام. چطوری؟"},
  ]
}

# # Make your request and handle the response
response = llm.run(api_request_json_farsi)
print(json.dumps(response.json(), indent=2))



decoded_response = response.json()
farsi_response = decoded_response['choices'][0]['message']['content']


print(farsi_response)


# Build the API request
api_request_json = {
    "messages": [
        {"role": "user", "content": "What is the weather like in Boston?"},
    ],
    "functions": [
        {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "days": {
                        "type": "number",
                        "description": "for how many days ahead you wants the forecast",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
            },
            "required": ["location", "days"],
        }
    ],
    "stream": False,
    "function_call": "get_current_weather",
}


# Build the API request
api_request_json_farsi = {
    "messages": [
        {"role": "user", "content": "سلام. چطوری"},
    ],
    "functions": [
        {
            "name": "farsi_llm_chatbot",
            "description": "Respond to the Farsi query in Farsi",
            # "parameters": {
            #     "type": "object",
            #     "properties": {
            #         "location": {
            #             "type": "string",
            #             "description": "The city and state, e.g. San Francisco, CA",
            #         },
            #         "days": {
            #             "type": "number",
            #             "description": "for how many days ahead you wants the forecast",
            #         },
            #         "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
            # #     },
            # },
            # "required": ["location", "days"],
        }
    ],
    "stream": False,
    # "function_call": "get_current_weather",
}








pruned_df = pd.read_csv('./pruned_data.csv')
pruned_df





queries_for_llm_df = pruned_df[["instruction", "input"]]
queries_for_llm_df





queries_for_llm_df["input"].fillna(" ", inplace=True)
queries_for_llm_df





queries_list = (queries_for_llm_df['instruction'].to_numpy() + queries_for_llm_df['input'].to_numpy()).tolist()
queries_list 





def generate_json_requests(contents):
    json_requests = []

    for content in contents:
        api_request_json_farsi = {
          "model": "llama-13b-chat",
          "messages": [
            {"role": "system", "content": "You are a Farsi chatbot. Respond to the Farsi query with a Farsi response."},
            {"role": "user", "content": content},
          ]
        }
        json_requests.append(api_request_json_farsi)

    return json_requests


json_requests = generate_json_requests(queries_list)
json_requests





# def get_llm_response(json_requests):
#     json_list = []
#     for request in json_requests:
#         print("here")
#         response = llm.run(request)
#         json_list.append(response)
        # print(json.dumps(response.json(), indent=2))
        # print("--------------------------------")
    # with open(output_file, 'w', encoding="utf-8") as f:
    # f.write(response + '\n')

    # return json_list


import time


response_list = []

for index, request in enumerate(json_requests):
    # if index > 3:
    #     continue
    print(f"Working on response number {index}")

    print(f"Request is:\n{request}")
    response = llm.run(request)
    decoded_response = response.json()
    farsi_response = decoded_response['choices'][0]['message']['content']
    response_list.append(farsi_response)

    time.sleep(4)


print(response_list)


pruned_df_w_answers = pruned_df.copy()


#Add a column to the new df to hold the responses
pruned_df_w_answers['llm_response'] = response_list


#Print the first row without any truncation
pd.set_option('display.max_colwidth', None)

pruned_df_w_answers.iloc[1]


#Rename the output column to 'bactrian-x-answer'
pruned_df_w_answers.rename(columns={'output':'bactrian-x-answer'}, inplace=True)


pruned_df_w_answers.rename(columns={'llm_response':'llama1-response'}, inplace=True)


#Save the df to a CSV file
pruned_df_w_answers.to_csv('pruned_data_w_llama1_responses.csv', index=False)








pd.set_option('display.max_colwidth', None)
llama1_response = pd.read_csv('pruned_data_w_llama1_responses.csv')
llama1_response


llama1_response['grammar_score'] = 0
llama1_response['content_score'] = 0
llama1_response


llama1_response.at[0, 'grammar_score'] = 1
llama1_response.at[0, 'content_score'] = 4

llama1_response.at[1, 'grammar_score'] = 3
llama1_response.at[1, 'content_score'] = 0

llama1_response.at[2, 'grammar_score'] = 3
llama1_response.at[2, 'content_score'] = 3

llama1_response.at[3, 'grammar_score'] = 4
llama1_response.at[3, 'content_score'] = 5

llama1_response.at[4, 'grammar_score'] = 2
llama1_response.at[4, 'content_score'] = 5

llama1_response.at[5, 'grammar_score'] = 4
llama1_response.at[5, 'content_score'] = 5

llama1_response.at[6, 'grammar_score'] = 5
llama1_response.at[6, 'content_score'] = 2

llama1_response.at[7, 'grammar_score'] = 1
llama1_response.at[7, 'content_score'] = 5

llama1_response.at[8, 'grammar_score'] = 2
llama1_response.at[8, 'content_score'] = 5

llama1_response.at[9, 'grammar_score'] = 4
llama1_response.at[9, 'content_score'] = 5

llama1_response.at[10, 'grammar_score'] = 1
llama1_response.at[10, 'content_score'] = 5

llama1_response.at[11, 'grammar_score'] = 0
llama1_response.at[11, 'content_score'] = 5

llama1_response.at[12, 'grammar_score'] = 0
llama1_response.at[12, 'content_score'] = 5

llama1_response.at[13, 'grammar_score'] = 2
llama1_response.at[13, 'content_score'] = 5

llama1_response.at[14, 'grammar_score'] = 0
llama1_response.at[14, 'content_score'] = 5

llama1_response.at[15, 'grammar_score'] = 4
llama1_response.at[15, 'content_score'] = 5

llama1_response.at[16, 'grammar_score'] = 1
llama1_response.at[16, 'content_score'] = 5

llama1_response.at[17,'grammar_score'] = 5
llama1_response.at[17,'content_score'] = 5

llama1_response.at[18, 'grammar_score'] = 0
llama1_response.at[18, 'content_score'] = 4

llama1_response.at[19, 'grammar_score'] = 4
llama1_response.at[19, 'content_score'] = 5

llama1_response.at[20, 'grammar_score'] = 4
llama1_response.at[20, 'content_score'] = 5

llama1_response.at[21, 'grammar_score'] = 5
llama1_response.at[21, 'content_score'] = 5

llama1_response.at[22, 'grammar_score'] = 2
llama1_response.at[22, 'content_score'] = 5

llama1_response.at[23, 'grammar_score'] = 4
llama1_response.at[23, 'content_score'] = 5

llama1_response.at[24, 'grammar_score'] = 3
llama1_response.at[24, 'content_score'] = 5

llama1_response.at[25, 'grammar_score'] = 0
llama1_response.at[25, 'content_score'] = 5

llama1_response.at[26, 'grammar_score'] = 4
llama1_response.at[26, 'content_score'] = 5

llama1_response.at[27, 'grammar_score'] = 4
llama1_response.at[27, 'content_score'] = 5

llama1_response.at[28, 'grammar_score'] = 1
llama1_response.at[28, 'content_score'] = 5

llama1_response.at[29, 'grammar_score'] = 3
llama1_response.at[29, 'content_score'] = 5


llama1_response


llama1_response.to_csv('llama1_response_w_scores.csv', index=False)



